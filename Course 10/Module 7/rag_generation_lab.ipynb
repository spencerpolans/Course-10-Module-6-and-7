{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare RAG System Lab\n",
    "## Overview\n",
    "\n",
    "In this lab, you'll take on the role of a junior data scientist at a healthcare technology company that specializes in creating educational resources for patients. Your team has been tasked with developing a system that can automatically generate informative responses to common patient questions about medical conditions, treatments, and wellness practices.\n",
    "\n",
    "The challenge is to ensure these responses are both accurate and grounded in authoritative medical information. Your specific assignment is to implement a Retrieval-Augmented Generation (RAG) system that can:\n",
    "1. Understand patient questions about various health topics\n",
    "2. Retrieve relevant information from a trusted knowledge base\n",
    "3. Generate helpful, accurate responses based on that information\n",
    "4. Avoid \"hallucinated\" content that could potentially misinform patients\n",
    "\n",
    "This lab follows the generative AI implementation process we've studied, with particular focus on:\n",
    "- Data Strategy and Knowledge Foundation\n",
    "- Model Selection and Generation Control\n",
    "- Evaluation Framework Development\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 0 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c58c12104e4f19a764601f0f67408d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Knowledge Base Setup\n",
    "\n",
    "Let's create a sample medical knowledge base with information about common health conditions, treatments, and wellness practices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base loaded with 10 entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diabetes is a chronic condition that affects h...</td>\n",
       "      <td>{'topic': 'diabetes', 'subtopic': 'overview', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type 1 diabetes is an autoimmune reaction that...</td>\n",
       "      <td>{'topic': 'diabetes', 'subtopic': 'type1', 'so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Diabetes is a chronic condition that affects h...   \n",
       "1  Type 1 diabetes is an autoimmune reaction that...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'topic': 'diabetes', 'subtopic': 'overview', ...  \n",
       "1  {'topic': 'diabetes', 'subtopic': 'type1', 'so...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample medical knowledge base\n",
    "knowledge_base = pd.DataFrame({\n",
    "    'content': [\n",
    "        \"Diabetes is a chronic condition that affects how your body turns food into energy. There are three main types: Type 1, Type 2, and gestational diabetes. Type 2 diabetes is the most common form, accounting for about 90-95% of diabetes cases.\",\n",
    "        \"Type 1 diabetes is an autoimmune reaction that stops your body from making insulin. Symptoms include increased thirst, frequent urination, hunger, fatigue, and blurred vision. It's usually diagnosed in children, teens, and young adults.\",\n",
    "        \"Type 2 diabetes occurs when your body becomes resistant to insulin or doesn't make enough insulin. Risk factors include being overweight, being 45 years or older, having a parent or sibling with type 2 diabetes, and being physically active less than 3 times a week.\",\n",
    "        \"Managing diabetes involves monitoring blood sugar levels, taking medications as prescribed, eating a healthy diet, maintaining a healthy weight, and getting regular physical activity. It's important to work with healthcare providers to develop a management plan.\",\n",
    "        \"Hypertension, or high blood pressure, is when the force of blood pushing against the walls of your arteries is consistently too high. It's often called the 'silent killer' because it typically has no symptoms but significantly increases the risk of heart disease and stroke.\",\n",
    "        \"Blood pressure is measured using two numbers: systolic (top number) and diastolic (bottom number). Normal blood pressure is less than 120/80 mm Hg. Hypertension is diagnosed when readings are consistently 130/80 mm Hg or higher.\",\n",
    "        \"Lifestyle changes to manage hypertension include reducing sodium in your diet, getting regular physical activity, maintaining a healthy weight, limiting alcohol, quitting smoking, and managing stress. Medications may also be prescribed if lifestyle changes aren't enough.\",\n",
    "        \"Regular physical activity offers numerous health benefits, including weight management, reduced risk of heart disease, strengthened bones and muscles, improved mental health, and enhanced ability to perform daily activities. Adults should aim for at least 150 minutes of moderate-intensity activity per week.\",\n",
    "        \"A balanced diet should include a variety of fruits, vegetables, whole grains, lean proteins, and healthy fats. It's recommended to limit intake of added sugars, sodium, saturated fats, and processed foods. Proper nutrition helps prevent chronic diseases and supports overall health.\",\n",
    "        \"Vaccination is one of the most effective ways to prevent infectious diseases. Vaccines work by helping the body recognize and fight specific pathogens. Common adult vaccines include influenza (flu), Tdap (tetanus, diphtheria, pertussis), shingles, and pneumococcal vaccines.\"\n",
    "    ],\n",
    "    'metadata': [\n",
    "        {'topic': 'diabetes', 'subtopic': 'overview', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'diabetes', 'subtopic': 'type1', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'diabetes', 'subtopic': 'type2', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'diabetes', 'subtopic': 'management', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
    "        {'topic': 'hypertension', 'subtopic': 'overview', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
    "        {'topic': 'hypertension', 'subtopic': 'diagnosis', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
    "        {'topic': 'hypertension', 'subtopic': 'management', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
    "        {'topic': 'wellness', 'subtopic': 'physical_activity', 'source': 'health_promotion', 'last_updated': '2023-05-15'},\n",
    "        {'topic': 'wellness', 'subtopic': 'nutrition', 'source': 'health_promotion', 'last_updated': '2023-05-15'},\n",
    "        {'topic': 'prevention', 'subtopic': 'vaccination', 'source': 'medical_guidelines', 'last_updated': '2023-08-05'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"Knowledge base loaded with {len(knowledge_base)} entries\")\n",
    "knowledge_base.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create Document Embeddings\n",
    "\n",
    "Complete the function below to create embeddings for each document in the knowledge base. These embeddings will be used to find relevant documents based on patient queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b28ebf54d04be5bd02dfe497309f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fe82ab85a04485ba2fce858e3784af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb0a7e2bac4bb5b89da8e707b31875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9eb5716c34466f833eae52b86d25c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76abfd36db374ae99baf904690741052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532b4ca9ce024e7f9398c0acbe828727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6411df673fdc49c8b765e9793b376965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7936417079974b7c921f6921d2f6dfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc1631aecdf4887aa971ea2ffaca5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76356f6078064436a5b1e00cd7eea0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93329b1beef43f887c608f74fbe9657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e11c1cb1974f7cbf359968dce74198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/218M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d35d8e03b4445fbcb166723f0e1a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b3dd3994a409398df442517972d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657319948d844706bd5a9a3d2bf24471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10552942f34e45bfb85f1ecfd73575cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d24b29c1014ab9ab0ada5fd7039cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d3b2135d7f434f864719eb65e387ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6218cc5fe6684df19982faf90cee9d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fdb55e3a974bd0a93b0630ee84d14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/742k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819094c80cb24244a3806a9c8b5d2e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b6c4dbcc8147b4b8c06ebcbe9dc4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d9bf86a2884ba2a92a778bbb45f1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3651276386424eb99e055bcd43f22a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c1b5652b28411981b74005da4b278c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d1b52609e54b8d857957fe3f830214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ca65e2f1344d7cb573bfb0deef915b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57460877d9a48999bdef362fe67af13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999a84c9d2bf498cb16826c317731f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (10, 768)\n"
     ]
    }
   ],
   "source": [
    "def create_document_embeddings(documents):\n",
    "    \"\"\"\n",
    "    Create embeddings for a list of documents.\n",
    "    \n",
    "    Args:\n",
    "        documents: List of text documents to embed\n",
    "        \n",
    "    Returns:\n",
    "        Numpy array of document embeddings\n",
    "    \"\"\"\n",
    "    # Initialize a sentence transformer model\n",
    "    # Recommended: 'sentence-transformers/all-mpnet-base-v2' or similar\n",
    "    embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')  # Replace with your code\n",
    "    \n",
    "    # Generate embeddings for all documents\n",
    "    # Hint: Use the model.encode() method\n",
    "    document_embeddings = embedding_model.encode(knowledge_base['content'].tolist(), show_progress_bar=True)  # Replace with your code\n",
    "    \n",
    "    return document_embeddings\n",
    "\n",
    "# Extract document content\n",
    "documents = knowledge_base['content'].tolist()\n",
    "\n",
    "# Create document embeddings\n",
    "document_embeddings = create_document_embeddings(documents)\n",
    "\n",
    "# Verify the shape of embeddings\n",
    "if document_embeddings is not None:\n",
    "    print(f\"Generated embeddings with shape: {document_embeddings.shape}\")\n",
    "else:\n",
    "    print(\"Embeddings not created yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing the Retrieval Component\n",
    "\n",
    "Now, let's implement the function to retrieve relevant documents based on a patient query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the symptoms of Type 1 diabetes?\n",
      "\n",
      "Retrieved Documents:\n",
      "1. [0.7585] Type 1 diabetes is an autoimmune reaction that stops your body from making insulin. Symptoms include...\n",
      "   Topic: diabetes, Subtopic: type1\n",
      "2. [0.4625] Diabetes is a chronic condition that affects how your body turns food into energy. There are three m...\n",
      "   Topic: diabetes, Subtopic: overview\n"
     ]
    }
   ],
   "source": [
    "def retrieve_documents(query, embeddings, contents, metadata, top_k=3, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant documents for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query: The patient's question\n",
    "        embeddings: The precomputed document embeddings\n",
    "        contents: The text content of the documents\n",
    "        metadata: The metadata for each document\n",
    "        top_k: Maximum number of documents to retrieve\n",
    "        threshold: Minimum similarity score to include a document\n",
    "        \n",
    "    Returns:\n",
    "        List of (content, metadata, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    # Get or initialize the embedding model (same as in create_document_embeddings)\n",
    "    embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    \n",
    "    # Embed the query\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    \n",
    "    # Calculate similarity scores between query and all documents\n",
    "    # Hint: Use cosine_similarity\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    \n",
    "    # Filter by threshold and get top k results\n",
    "    # Hint: Use list comprehension, sorting, and slicing\n",
    "    filtered_indices = [i for i, score in enumerate(similarities) if score >= threshold]\n",
    "    top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]\n",
    "    # Return the top documents with their metadata and scores\n",
    "    results = [(contents[i], metadata[i], similarities[i]) for i in top_indices]\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the retrieval function with a sample query\n",
    "if document_embeddings is not None:\n",
    "    sample_query = \"What are the symptoms of Type 1 diabetes?\"\n",
    "    retrieved_docs = retrieve_documents(\n",
    "        query=sample_query,\n",
    "        embeddings=document_embeddings,\n",
    "        contents=documents,\n",
    "        metadata=knowledge_base['metadata'].tolist(),\n",
    "        top_k=2\n",
    "    )\n",
    "    \n",
    "    print(f\"Query: {sample_query}\")\n",
    "    print(\"\\nRetrieved Documents:\")\n",
    "    for i, (content, meta, score) in enumerate(retrieved_docs):\n",
    "        print(f\"{i+1}. [{score:.4f}] {content[:100]}...\")\n",
    "        print(f\"   Topic: {meta['topic']}, Subtopic: {meta['subtopic']}\")\n",
    "else:\n",
    "    print(\"Cannot test retrieval without document embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Generation Component\n",
    "\n",
    "Now, let's implement the generation component that will use the retrieved documents to create informative responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized gpt2 with 124439808 parameters\n"
     ]
    }
   ],
   "source": [
    "# Initialize the generative model\n",
    "def initialize_generator(model_name=\"gpt2\"):\n",
    "    \"\"\"\n",
    "    Initialize the generative model and tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the pretrained model to use\n",
    "        \n",
    "    Returns:\n",
    "        Tokenizer and model objects\n",
    "    \"\"\"\n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)  # Replace with your code\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)  # Replace with your code\n",
    "    \n",
    "    # Set padding token if needed\n",
    "    # Check if pad_token exists, if not set it to eos_token\n",
    "    # Set pad token for batch processing\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "# Initialize the generator\n",
    "tokenizer, model = initialize_generator()\n",
    "if tokenizer and model:\n",
    "    print(f\"Initialized {model.config._name_or_path} with {model.num_parameters()} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What are the different types of diabetes?\n",
      "\n",
      "Retrieved Documents:\n",
      "1. [0.7130] Topic: diabetes, Subtopic: overview\n",
      "2. [0.6430] Topic: diabetes, Subtopic: type1\n",
      "\n",
      "Generated Response:\n",
      "Context information:\n",
      "- Diabetes is a chronic condition that affects how your body turns food into energy. There are three main types: Type 1, Type 2, and gestational diabetes. Type 2 diabetes is the most common form, accounting for about 90-95% of diabetes cases.\n",
      "- Type 1 diabetes is an autoimmune reaction that stops your body from making insulin. Symptoms include increased thirst, frequent urination, hunger, fatigue, and blurred vision. It's usually diagnosed in children, teens, and young adults.\n",
      "\n",
      "Question: What are the different types of diabetes?\n",
      "Answer: Type 1 diabetes is a chronic condition that affects how your body turns food into energy. There are three main types: Type 1, Type 2, and gestational diabetes. Type 2 diabetes is the most common form, accounting for about 90-95% of diabetes cases.\n",
      "\n",
      "- Type 1 diabetes is an autoimmune reaction that stops your body from making insulin. Symptoms include increased thirst, frequent urination, hunger, fatigue, and blurred vision. It's usually diagnosed in children, teens, and young\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: How can I manage my high blood pressure through lifestyle changes?\n",
      "\n",
      "Retrieved Documents:\n",
      "1. [0.7775] Topic: hypertension, Subtopic: management\n",
      "2. [0.4690] Topic: hypertension, Subtopic: overview\n",
      "\n",
      "Generated Response:\n",
      "Context information:\n",
      "- Lifestyle changes to manage hypertension include reducing sodium in your diet, getting regular physical activity, maintaining a healthy weight, limiting alcohol, quitting smoking, and managing stress. Medications may also be prescribed if lifestyle changes aren't enough.\n",
      "- Hypertension, or high blood pressure, is when the force of blood pushing against the walls of your arteries is consistently too high. It's often called the'silent killer' because it typically has no symptoms but significantly increases the risk of heart disease and stroke.\n",
      "\n",
      "Question: How can I manage my high blood pressure through lifestyle changes?\n",
      "Answer: You can manage your blood pressure through lifestyle changes using a diet and exercise program (such as a dietitian) or a lifestyle intervention program (such as an exercise program).\n",
      "\n",
      "Question: If I'm overweight, can I get regular physical activity and get regular exercise?\n",
      "\n",
      "Answer: You can get regular exercise and get regular exercise from your health care provider.\n",
      "\n",
      "Question: I'm overweight, but my cholesterol is low. How do I get regular exercise?\n",
      "\n",
      "Answer: You\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Why is regular physical activity important for health?\n",
      "\n",
      "Retrieved Documents:\n",
      "1. [0.7906] Topic: wellness, Subtopic: physical_activity\n",
      "2. [0.3873] Topic: wellness, Subtopic: nutrition\n",
      "\n",
      "Generated Response:\n",
      "Context information:\n",
      "- Regular physical activity offers numerous health benefits, including weight management, reduced risk of heart disease, strengthened bones and muscles, improved mental health, and enhanced ability to perform daily activities. Adults should aim for at least 150 minutes of moderate-intensity activity per week.\n",
      "- A balanced diet should include a variety of fruits, vegetables, whole grains, lean proteins, and healthy fats. It's recommended to limit intake of added sugars, sodium, saturated fats, and processed foods. Proper nutrition helps prevent chronic diseases and supports overall health.\n",
      "\n",
      "Question: Why is regular physical activity important for health?\n",
      "Answer: Regular physical activity is associated with lower risk of cardiovascular disease. Studies suggest that regular physical activity can lead to lower blood pressure, lower cholesterol, and better health than short-term exercise.\n",
      "\n",
      "Question: How do I reduce my risk of developing cardiovascular disease?\n",
      "\n",
      "Answer: Regular physical activity may reduce your risk of developing cardiovascular disease. The main goal of regular physical activity is to decrease your risk of developing cardiovascular disease.\n",
      "\n",
      "Question: Why is regular physical activity more effective at reducing my risk\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: What vaccines should adults consider getting?\n",
      "\n",
      "Retrieved Documents:\n",
      "1. [0.6329] Topic: prevention, Subtopic: vaccination\n",
      "\n",
      "Generated Response:\n",
      "Context information:\n",
      "- Vaccination is one of the most effective ways to prevent infectious diseases. Vaccines work by helping the body recognize and fight specific pathogens. Common adult vaccines include influenza (flu), Tdap (tetanus, diphtheria, pertussis), shingles, and pneumococcal vaccines.\n",
      "\n",
      "Question: What vaccines should adults consider getting?\n",
      "Answer: The CDC recommends avoiding any vaccine that has been given to people with a history of measles, mumps, rubella, or rubella (MMR-V). This includes any vaccines that have not been used for years, such as vaccines for children who have not had their vaccination tested for measles, mumps, rubella, or rubella.\n",
      "\n",
      "Question: Is there a safe level of vaccine?\n",
      "\n",
      "Answer: The CDC recommends that adults take at least one dose of all of the\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generate_rag_response(query, contents, metadata, document_embeddings, tokenizer, model, max_length=100):\n",
    "    \"\"\"\n",
    "    Generate a response using Retrieval-Augmented Generation.\n",
    "    \n",
    "    Args:\n",
    "        query: The patient's question\n",
    "        contents: List of document contents\n",
    "        metadata: List of document metadata\n",
    "        document_embeddings: Precomputed embeddings for the documents\n",
    "        tokenizer: The tokenizer for the language model\n",
    "        model: The language model for generation\n",
    "        max_length: Maximum response length\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with the generated response and the retrieved documents\n",
    "    \"\"\"\n",
    "    # Retrieve relevant documents for the query\n",
    "    retrieved_docs = retrieve_documents(\n",
    "        query, \n",
    "        document_embeddings,\n",
    "        contents,\n",
    "        metadata, \n",
    "        top_k=2\n",
    "    )  \n",
    "    \n",
    "    # Format prompt with retrieved context\n",
    "    # Hint: If no relevant documents are found, generate without context\n",
    "    # Otherwise, include retrieved documents as context\n",
    "    if not retrieved_docs:\n",
    "         prompt = f\"Question: {query}\\nAnswer:\"\n",
    "    else:\n",
    "        # Format prompt with retrieved context\n",
    "        context = \"\\n\".join([f\"- {doc[0]}\" for doc in retrieved_docs])\n",
    "        prompt = f\"Context information:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)  \n",
    "    \n",
    "    # TGenerate the response\n",
    "    # Consider including temperature, top_k, and do_sample parameters (will otherwise use greedy method)\n",
    "    output_sequences =  output_sequences = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=len(inputs[\"input_ids\"][0]) + max_length,\n",
    "            temperature=0.7,\n",
    "            top_k=10,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )  # Replace with your code\n",
    "    \n",
    "    # Decode the response and extract the generated text\n",
    "    response = tokenizer.decode(output_sequences[0], skip_special_tokens=True)  # Replace with your code\n",
    "    \n",
    "    # Return the results\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"retrieved_documents\": retrieved_docs\n",
    "    }\n",
    "\n",
    "# Test the RAG system with several queries\n",
    "if document_embeddings is not None and tokenizer and model:\n",
    "    test_queries = [\n",
    "        \"What are the different types of diabetes?\",\n",
    "        \"How can I manage my high blood pressure through lifestyle changes?\",\n",
    "        \"Why is regular physical activity important for health?\",\n",
    "        \"What vaccines should adults consider getting?\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        result = generate_rag_response(\n",
    "            query=query,\n",
    "            contents=documents,\n",
    "            metadata=knowledge_base['metadata'].tolist(),\n",
    "            document_embeddings=document_embeddings,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        print(\"\\nRetrieved Documents:\")\n",
    "        for i, (doc, meta, score) in enumerate(result[\"retrieved_documents\"]):\n",
    "            print(f\"{i+1}. [{score:.4f}] Topic: {meta['topic']}, Subtopic: {meta['subtopic']}\")\n",
    "        \n",
    "        print(f\"\\nGenerated Response:\\n{result['response']}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"Cannot test generation without embeddings or model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation and Analysis\n",
    "\n",
    "Let's implement a basic evaluation function to assess the quality of our generated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the different types of diabetes?\n",
      "Evaluation Metrics: {'content_overlap': 1.0, 'length_score': 1.0, 'overall_score': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "Query: How can I manage my high blood pressure through lifestyle changes?\n",
      "Evaluation Metrics: {'content_overlap': 1.0, 'length_score': 1.0, 'overall_score': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "Query: Why is regular physical activity important for health?\n",
      "Evaluation Metrics: {'content_overlap': 1.0, 'length_score': 1.0, 'overall_score': 1.0}\n",
      "--------------------------------------------------------------------------------\n",
      "Query: What vaccines should adults consider getting?\n",
      "Evaluation Metrics: {'content_overlap': 1.0, 'length_score': 1.0, 'overall_score': 1.0}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_response(response_data, evaluation_criteria=None):\n",
    "    \"\"\"\n",
    "    Evaluate the quality of a generated response based on various criteria.\n",
    "    \n",
    "    Args:\n",
    "        response_data: Dictionary containing the query, response, and retrieved docs\n",
    "        \n",
    "    Returns:\n",
    "        Evaluation metrics\n",
    "    \"\"\"\n",
    "    # Implement at least two evaluation metrics\n",
    "    # Suggestions:\n",
    "    # 1. Content relevance - Check if response mentions terms from retrieved docs\n",
    "    # 2. Response length appropriateness - Check if length is suitable for query\n",
    "    # 3. Medical terminology usage - Check if appropriate medical terms are included\n",
    "    medical_terms = [\n",
    "        \"diabetes\", \"insulin\", \"glucose\", \"hypertension\", \"blood pressure\",\n",
    "        \"systolic\", \"diastolic\", \"cardiovascular\", \"cholesterol\", \"nutrition\",\n",
    "        \"obesity\", \"physical activity\", \"vaccination\", \"immune\", \"prevention\"\n",
    "    ]\n",
    "    \n",
    "    if evaluation_criteria is None:\n",
    "        # Default evaluation - check if response mentions content from retrieved docs\n",
    "        retrieved_content = [doc[0].lower() for doc in response_data[\"retrieved_documents\"]]\n",
    "        response_lower = response_data[\"response\"].lower()\n",
    "        \n",
    "        # Simple content overlap check\n",
    "        content_overlap = sum(1 for doc in retrieved_content if any(\n",
    "            term in response_lower for term in doc.split()[:5]\n",
    "        )) / max(1, len(retrieved_content))\n",
    "        \n",
    "        # Length appropriateness (simple heuristic)\n",
    "        query_words = len(response_data[\"query\"].split())\n",
    "        response_words = len(response_data[\"response\"].split())\n",
    "        length_score = min(1.0, response_words / (query_words * 3))\n",
    "\n",
    "        metrics = {\n",
    "            \"content_overlap\": content_overlap,\n",
    "            \"length_score\": length_score,\n",
    "            \"overall_score\": (content_overlap + length_score) / 2\n",
    "        }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate the responses for our test queries\n",
    "if 'test_queries' in locals() and document_embeddings is not None and tokenizer and model:\n",
    "    for query in test_queries:\n",
    "        result = generate_rag_response(\n",
    "            query=query,\n",
    "            contents=documents,\n",
    "            metadata=knowledge_base['metadata'].tolist(),\n",
    "            document_embeddings=document_embeddings,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        metrics = evaluate_response(result)\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Evaluation Metrics: {metrics}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"Cannot evaluate without test queries or necessary components.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer the following questions about your RAG implementation and its potential applications in healthcare:\n",
    "\n",
    "### How does the RAG approach improve factual accuracy compared to regular generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) maintains a knowledge base of trusted information. It rlies on domain specific (ie medical) docs which help for response generation.\n",
    "2) Retrieves relevant docs based on the task: the system will search to get the most relevant documents.\n",
    "3) Include retrieved information in the model's context window: Essentially, it looks at helpful docs and \"reads\" them before replying\n",
    "4) Generate content that draws on the model's knowledge and retreived info: it uses what it knows plus the documents it has to give a better/more accurate answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are potential challenges or limitations of your current implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The model is limited by the knowledge base we have given it.\n",
    "2) The knowledge in it is not updated so it is not getting updates as knowledge changes\n",
    "3) It does not actually understand its output, it is just giving us patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How might you enhance this system for a production healthcare environment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the knowledge base is so small, I would integrate a much larger medical knowledge base and continuously update it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What ethical considerations are particularly important for healthcare content generation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It needs to be accurate. We have talked in our live sessions about how what determines a good model is discipline dependent. Well, in healthcare, getting wrong information can lead to very bad outcomes. We need to provide the model with as much information as possible.\n",
    "\n",
    "I saw an instagram video the other day about AI. Though silly, it was saying how in a future, an organic (human made) movie was an option versus an AI generated film. We need to make sure that the users know they are talking to an AI because, as we have seen, sometimes it is difficult to tell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
